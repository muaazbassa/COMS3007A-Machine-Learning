{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.334375\n",
      "Unseen Data Accuracy: 0.3795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train_data = np.genfromtxt('traindata.txt', delimiter=',')\n",
    "train_labels = np.loadtxt('trainlabels.txt')\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, unseen_data, train_labels, unseen_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the labels for the validation and unseen data\n",
    "val_predictions = classifier.predict(val_data)\n",
    "unseen_predictions = classifier.predict(unseen_data)\n",
    "\n",
    "# Calculate and print the accuracy on the validation and unseen data\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "unseen_accuracy = accuracy_score(unseen_labels, unseen_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Unseen Data Accuracy:\", unseen_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 50, 'n_estimators': 500}\n",
      "Validation Accuracy: 0.40265625\n",
      "Validation Accuracy: 0.42375\n",
      "Unseen Data Accuracy: 0.4485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train_data = np.genfromtxt('traindata.txt', delimiter=',')\n",
    "train_labels = np.loadtxt('trainlabels.txt')\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, unseen_data, train_labels, unseen_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "unseen_data = scaler.transform(unseen_data)\n",
    "\n",
    "# Remove correlated features\n",
    "corr_matrix = pd.DataFrame(train_data).corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "train_data = np.delete(train_data, to_drop, axis=1)\n",
    "val_data = np.delete(val_data, to_drop, axis=1)\n",
    "unseen_data = np.delete(unseen_data, to_drop, axis=1)\n",
    "\n",
    "# Remove low-variance features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "train_data = selector.fit_transform(train_data)\n",
    "val_data = selector.transform(val_data)\n",
    "unseen_data = selector.transform(unseen_data)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 20, None]\n",
    "# }\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [20]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "\n",
    "# Train the grid search object\n",
    "grid_search.fit(train_data, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and their validation accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Create a Random Forest classifier with the best hyperparameters\n",
    "best_classifier = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                          max_depth=grid_search.best_params_['max_depth'], \n",
    "                                          random_state=42)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the labels for the validation and unseen data using the best classifier\n",
    "val_predictions = best_classifier.predict(val_data)\n",
    "unseen_predictions = best_classifier.predict(unseen_data)\n",
    "\n",
    "# Calculate and print the accuracy on the validation and unseen data\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "unseen_accuracy = accuracy_score(unseen_labels, unseen_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Unseen Data Accuracy:\", unseen_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 100, 'n_estimators': 1000}\n",
      "Validation Accuracy: 0.41734375\n",
      "Validation Accuracy: 0.44375\n",
      "Unseen Data Accuracy: 0.461\n",
      "Early stopping after epoch 5\n",
      "Validation Accuracy: 0.44375\n",
      "Unseen Data Accuracy: 0.461\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train_data = np.genfromtxt('traindata.txt', delimiter=',')\n",
    "train_labels = np.loadtxt('trainlabels.txt')\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, unseen_data, train_labels, unseen_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "unseen_data = scaler.transform(unseen_data)\n",
    "\n",
    "# Remove correlated features\n",
    "corr_matrix = pd.DataFrame(train_data).corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "train_data = np.delete(train_data, to_drop, axis=1)\n",
    "val_data = np.delete(val_data, to_drop, axis=1)\n",
    "unseen_data = np.delete(unseen_data, to_drop, axis=1)\n",
    "\n",
    "# Remove low-variance features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "train_data = selector.fit_transform(train_data)\n",
    "val_data = selector.transform(val_data)\n",
    "unseen_data = selector.transform(unseen_data)\n",
    "\n",
    "# Scale the features to a specific range\n",
    "# Here, we are scaling the features to the range [0, 1]\n",
    "min_val = np.min(train_data, axis=0)\n",
    "max_val = np.max(train_data, axis=0)\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "val_data = (val_data - min_val) / (max_val - min_val)\n",
    "unseen_data = (unseen_data - min_val) / (max_val - min_val)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [100]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "\n",
    "# Train the grid search object\n",
    "grid_search.fit(train_data, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and their validation accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Create a Random Forest classifier with the best hyperparameters\n",
    "best_classifier = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                          max_depth=grid_search.best_params_['max_depth'], \n",
    "                                          random_state=42)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the labels for the validation and unseen data using the best classifier\n",
    "val_predictions = best_classifier.predict(val_data)\n",
    "unseen_predictions = best_classifier.predict(unseen_data)\n",
    "\n",
    "# Calculate and print the accuracy on the validation and unseen data\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "unseen_accuracy = accuracy_score(unseen_labels, unseen_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Unseen Data Accuracy:\", unseen_accuracy)\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier with the best hyperparameters\n",
    "best_classifier = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                          max_depth=grid_search.best_params_['max_depth'], \n",
    "                                          random_state=42)\n",
    "\n",
    "# Train the classifier with early stopping\n",
    "best_score = 0\n",
    "best_epoch = 0\n",
    "patience = 5\n",
    "for epoch in range(100):\n",
    "    best_classifier.fit(train_data, train_labels)\n",
    "    val_predictions = best_classifier.predict(val_data)\n",
    "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    if val_accuracy > best_score:\n",
    "        best_score = val_accuracy\n",
    "        best_epoch = epoch\n",
    "    elif epoch - best_epoch >= patience:\n",
    "        print(\"Early stopping after epoch\", epoch)\n",
    "        break\n",
    "\n",
    "# Predict the labels for the validation and unseen data using the best classifier\n",
    "val_predictions = best_classifier.predict(val_data)\n",
    "unseen_predictions = best_classifier.predict(unseen_data)\n",
    "\n",
    "# Calculate and print the accuracy on the validation and unseen data\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "unseen_accuracy = accuracy_score(unseen_labels, unseen_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Unseen Data Accuracy:\", unseen_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Validation Accuracy: 0.35484375\n",
      "Validation Accuracy: 0.3825\n",
      "Unseen Data Accuracy: 0.3945\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train_data = np.genfromtxt('traindata.txt', delimiter=',')\n",
    "train_labels = np.loadtxt('trainlabels.txt')\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, unseen_data, train_labels, unseen_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "unseen_data = scaler.transform(unseen_data)\n",
    "\n",
    "# Remove correlated features\n",
    "corr_matrix = pd.DataFrame(train_data).corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "train_data = np.delete(train_data, to_drop, axis=1)\n",
    "val_data = np.delete(val_data, to_drop, axis=1)\n",
    "unseen_data = np.delete(unseen_data, to_drop, axis=1)\n",
    "\n",
    "# Remove low-variance features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "train_data = selector.fit_transform(train_data)\n",
    "val_data = selector.transform(val_data)\n",
    "unseen_data = selector.transform(unseen_data)\n",
    "\n",
    "# Generate polynomial features for the selected features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_data_poly = poly.fit_transform(train_data[:, [0, 2]])\n",
    "val_data_poly = poly.transform(val_data[:, [0, 2]])\n",
    "unseen_data_poly = poly.transform(unseen_data[:, [0, 2]])\n",
    "\n",
    "# Add the generated polynomial features to the dataset\n",
    "train_data = np.concatenate((train_data, train_data_poly), axis=1)\n",
    "val_data = np.concatenate((val_data, val_data_poly), axis=1)\n",
    "unseen_data = np.concatenate((unseen_data, unseen_data_poly), axis=1)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [20]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "\n",
    "# Train the grid search object\n",
    "grid_search.fit(train_data, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and their validation accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Create a Random Forest classifier with the best hyperparameters\n",
    "best_classifier = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                          max_depth=grid_search.best_params_['max_depth'], \n",
    "                                          random_state=42)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the labels for the validation and unseen data using the best classifier\n",
    "val_predictions = best_classifier.predict(val_data)\n",
    "unseen_predictions = best_classifier.predict(unseen_data)\n",
    "\n",
    "# Calculate and print the accuracy on the validation and unseen data\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "unseen_accuracy = accuracy_score(unseen_labels, unseen_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Unseen Data Accuracy:\", unseen_accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.3649472630023958\n",
      "Validation Loss: 2.247571759223938\n",
      "Epoch [2/50], Loss: 2.2175538611412047\n",
      "Validation Loss: 2.190909938812256\n",
      "Epoch [3/50], Loss: 2.1573812329769133\n",
      "Validation Loss: 2.1537196016311646\n",
      "Epoch [4/50], Loss: 2.1097389388084413\n",
      "Validation Loss: 2.116653664112091\n",
      "Epoch [5/50], Loss: 2.0499336910247803\n",
      "Validation Loss: 2.0933871030807496\n",
      "Epoch [6/50], Loss: 2.0078112477064134\n",
      "Validation Loss: 2.051489760875702\n",
      "Epoch [7/50], Loss: 1.977400752902031\n",
      "Validation Loss: 2.0149634504318237\n",
      "Epoch [8/50], Loss: 1.9455343747138978\n",
      "Validation Loss: 1.9862100958824158\n",
      "Epoch [9/50], Loss: 1.910859557390213\n",
      "Validation Loss: 1.954639995098114\n",
      "Epoch [10/50], Loss: 1.8744046711921691\n",
      "Validation Loss: 1.9266823244094848\n",
      "Epoch [11/50], Loss: 1.8166216152906418\n",
      "Validation Loss: 1.9193699669837951\n",
      "Epoch [12/50], Loss: 1.8208249682188034\n",
      "Validation Loss: 1.9141188549995423\n",
      "Epoch [13/50], Loss: 1.8179168301820754\n",
      "Validation Loss: 1.910422031879425\n",
      "Epoch [14/50], Loss: 1.806462236046791\n",
      "Validation Loss: 1.9109723496437072\n",
      "Epoch [15/50], Loss: 1.8022572350502015\n",
      "Validation Loss: 1.9058281326293944\n",
      "Epoch [16/50], Loss: 1.797824073433876\n",
      "Validation Loss: 1.909144515991211\n",
      "Epoch [17/50], Loss: 1.7873393630981445\n",
      "Validation Loss: 1.9060336661338806\n",
      "Epoch [18/50], Loss: 1.7876037353277205\n",
      "Validation Loss: 1.903714394569397\n",
      "Epoch [19/50], Loss: 1.7837731647491455\n",
      "Validation Loss: 1.8994276475906373\n",
      "Epoch [20/50], Loss: 1.7945612168312073\n",
      "Validation Loss: 1.8992122912406921\n",
      "Epoch [21/50], Loss: 1.7814382499456405\n",
      "Validation Loss: 1.8968765211105347\n",
      "Epoch [22/50], Loss: 1.7723158299922943\n",
      "Validation Loss: 1.8979786920547486\n",
      "Epoch [23/50], Loss: 1.7801908361911774\n",
      "Validation Loss: 1.898854591846466\n",
      "Epoch [24/50], Loss: 1.7811092728376388\n",
      "Validation Loss: 1.8969106769561768\n",
      "Epoch [25/50], Loss: 1.7667368483543395\n",
      "Validation Loss: 1.896367163658142\n",
      "Epoch [26/50], Loss: 1.7641467535495758\n",
      "Validation Loss: 1.896108522415161\n",
      "Epoch [27/50], Loss: 1.767355141043663\n",
      "Validation Loss: 1.8957729649543762\n",
      "Epoch [28/50], Loss: 1.7719362699985504\n",
      "Validation Loss: 1.8976766538619996\n",
      "Epoch [29/50], Loss: 1.7714021402597426\n",
      "Validation Loss: 1.8971127080917358\n",
      "Epoch [30/50], Loss: 1.7732111775875092\n",
      "Validation Loss: 1.8973770070075988\n",
      "Epoch [31/50], Loss: 1.774199297428131\n",
      "Validation Loss: 1.8963088154792787\n",
      "Epoch [32/50], Loss: 1.771597769856453\n",
      "Validation Loss: 1.8930452132225037\n",
      "Epoch [33/50], Loss: 1.77119140625\n",
      "Validation Loss: 1.89443532705307\n",
      "Epoch [34/50], Loss: 1.7686992609500884\n",
      "Validation Loss: 1.896952736377716\n",
      "Epoch [35/50], Loss: 1.7675168579816818\n",
      "Validation Loss: 1.8907124137878417\n",
      "Epoch [36/50], Loss: 1.7625437676906586\n",
      "Validation Loss: 1.8948881530761719\n",
      "Epoch [37/50], Loss: 1.7728210484981537\n",
      "Validation Loss: 1.8950264167785644\n",
      "Epoch [38/50], Loss: 1.7714079880714417\n",
      "Validation Loss: 1.8935307955741882\n",
      "Epoch [39/50], Loss: 1.7771085757017135\n",
      "Validation Loss: 1.8942856788635254\n",
      "Epoch [40/50], Loss: 1.7654463648796082\n",
      "Validation Loss: 1.895385239124298\n",
      "Early stopping.\n",
      "Validation Accuracy: 0.296875\n",
      "Accuracy of the network on the unseen data: 32 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('traindata.txt', header=None, delimiter=',')\n",
    "X = df.values\n",
    "\n",
    "# Load the labels\n",
    "y = pd.read_csv('trainlabels.txt', header=None).values.ravel()\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "X_train, X_unseen, y_train, y_unseen = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define your model using PyTorch's nn.Module\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=X.shape[1], out_features=64)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.bn2(torch.relu(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "X_unseen = torch.tensor(X_unseen, dtype=torch.float32)\n",
    "y_unseen = torch.tensor(y_unseen, dtype=torch.long)\n",
    "\n",
    "# Convert the tensors into datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "unseen_dataset = TensorDataset(X_unseen, y_unseen)\n",
    "\n",
    "# Convert the datasets into dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "unseen_loader = DataLoader(unseen_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Create an instance of your model\n",
    "model = Classifier()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "no_improve = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve == 5:\n",
    "            print('Early stopping.')\n",
    "            break\n",
    "    scheduler.step()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predict the labels for the validation data\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val)\n",
    "    _, val_predicted_labels = torch.max(val_predictions, 1)\n",
    "\n",
    "# Calculate and print the accuracy on the validation data\n",
    "val_accuracy = accuracy_score(y_val, val_predicted_labels)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Evaluation on unseen data\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in unseen_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the unseen data: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0             1             2             3             4   \\\n",
      "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean       0.003283      0.045539     -0.001024     -0.002836      0.018141   \n",
      "std        0.545496      0.583899      0.543287      0.546328      0.567012   \n",
      "min       -2.230000     -2.240000     -2.210000     -1.830000     -2.270000   \n",
      "25%       -0.370000     -0.340000     -0.370000     -0.380000     -0.350000   \n",
      "50%       -0.000000      0.030000     -0.000000     -0.010000      0.010000   \n",
      "75%        0.360000      0.420000      0.360000      0.360000      0.390000   \n",
      "max        2.110000      2.370000      2.380000      2.050000      2.830000   \n",
      "\n",
      "                 5             6             7            8             9   \\\n",
      "count  10000.000000  10000.000000  10000.000000  10000.00000  10000.000000   \n",
      "mean       0.003151     -0.003583     -0.006363      0.14467      0.544114   \n",
      "std        0.565869      0.545105      0.551033      0.65011      0.743096   \n",
      "min       -2.020000     -1.970000     -2.190000     -2.30000     -2.120000   \n",
      "25%       -0.380000     -0.370000     -0.380000     -0.30000      0.010000   \n",
      "50%       -0.000000      0.000000      0.000000      0.10000      0.540000   \n",
      "75%        0.380000      0.360000      0.360000      0.54000      1.080000   \n",
      "max        2.520000      1.980000      2.130000      2.77000      3.040000   \n",
      "\n",
      "       ...            61            62            63            64  \\\n",
      "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean   ...      0.121473      0.002367      0.003018      1.500600   \n",
      "std    ...      0.636421      0.548940      0.552322      1.113968   \n",
      "min    ...     -2.060000     -2.180000     -2.280000      0.000000   \n",
      "25%    ...     -0.320000     -0.370000     -0.380000      1.000000   \n",
      "50%    ...      0.090000     -0.000000     -0.000000      1.000000   \n",
      "75%    ...      0.510000      0.370000      0.370000      2.000000   \n",
      "max    ...      2.680000      2.780000      2.190000      3.000000   \n",
      "\n",
      "                 65            66            67            68            69  \\\n",
      "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean       4.539100      4.488300      4.464600      4.503400      0.006400   \n",
      "std        2.856482      2.880849      2.881593      2.874198      0.819894   \n",
      "min        0.000000      0.000000      0.000000      0.000000     -1.000000   \n",
      "25%        2.000000      2.000000      2.000000      2.000000     -1.000000   \n",
      "50%        5.000000      4.000000      4.000000      5.000000      0.000000   \n",
      "75%        7.000000      7.000000      7.000000      7.000000      1.000000   \n",
      "max        9.000000      9.000000      9.000000      9.000000      1.000000   \n",
      "\n",
      "                 70  \n",
      "count  10000.000000  \n",
      "mean       0.015400  \n",
      "std        0.815861  \n",
      "min       -1.000000  \n",
      "25%       -1.000000  \n",
      "50%        0.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 71 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_data = pd.read_csv('traindata.txt', header=None)\n",
    "train_labels = pd.read_csv('trainlabels.txt', header=None)\n",
    "print(train_data.describe())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nn', MLPClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "parameters = {\n",
    "    'nn__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'nn__activation': ['relu', 'tanh'],\n",
    "    'nn__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'nn__alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(train_data, train_labels.values.ravel())\n",
    "\n",
    "# Print the best hyperparameters and the accuracy\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9698333333333333\n",
      "Validation accuracy:  0.2215\n",
      "Test accuracy:  0.2475\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load the training data and labels\n",
    "train_data = pd.read_csv('traindata.txt', header=None)\n",
    "train_labels = pd.read_csv('trainlabels.txt', header=None)\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.4, random_state=42)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(val_data, val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "val_data_scaled = scaler.transform(val_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Train a neural network classifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', learning_rate_init=0.01, alpha=0.001, random_state=42)\n",
    "clf.fit(train_data_scaled, train_labels.values.ravel())\n",
    "\n",
    "# Evaluate the performance on the training, validation, and unseen data\n",
    "train_acc = clf.score(train_data_scaled, train_labels)\n",
    "val_acc = clf.score(val_data_scaled, val_labels)\n",
    "test_acc = clf.score(test_data_scaled, test_labels)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the training data and labels\n",
    "train_data = pd.read_csv('traindata.txt', header=None)\n",
    "train_labels = pd.read_csv('trainlabels.txt', header=None)\n",
    "\n",
    "# Split the data into training, validation, and unseen data\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.4, random_state=42)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(val_data, val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "val_data_scaled = scaler.transform(val_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nn', MLPClassifier(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "parameters = {\n",
    "    'nn__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100), (100, 50, 25)],\n",
    "    'nn__activation': ['relu', 'tanh'],\n",
    "    'nn__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'nn__alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "grid_search.fit(train_data, train_labels.values.ravel())\n",
    "\n",
    "# Print the best hyperparameters and the accuracy\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Train a deep neural network classifier with the best hyperparameters\n",
    "clf = MLPClassifier(**grid_search.best_params_, max_iter=10000, random_state=42)\n",
    "clf.fit(train_data_scaled, train_labels.values.ravel())\n",
    "\n",
    "# Evaluate the performance on the training, validation, and unseen data\n",
    "train_acc = clf.score(train_data_scaled, train_labels)\n",
    "val_acc = clf.score(val_data_scaled, val_labels)\n",
    "test_acc = clf.score(test_data_scaled, test_labels)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_177 (Dense)           (None, 64)                4608      \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,594\n",
      "Trainable params: 23,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 1s 885us/step - loss: 0.0886 - accuracy: 0.1491\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 884us/step - loss: 0.0860 - accuracy: 0.2070\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 886us/step - loss: 0.0828 - accuracy: 0.2583\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 934us/step - loss: 0.0797 - accuracy: 0.2987\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 891us/step - loss: 0.0776 - accuracy: 0.3288\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0755 - accuracy: 0.3550\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0736 - accuracy: 0.3736\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0718 - accuracy: 0.3970\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.4077\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0692 - accuracy: 0.4212\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0687 - accuracy: 0.4244\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0679 - accuracy: 0.4325\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0663 - accuracy: 0.4471\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0658 - accuracy: 0.4529\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0655 - accuracy: 0.4541\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0643 - accuracy: 0.4660\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0637 - accuracy: 0.4710\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0630 - accuracy: 0.4773\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0627 - accuracy: 0.4830\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0625 - accuracy: 0.4848\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.4750\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0628 - accuracy: 0.4826\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0625 - accuracy: 0.4831\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0607 - accuracy: 0.4993\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0613 - accuracy: 0.4915\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0612 - accuracy: 0.4938\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0626 - accuracy: 0.4843\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0613 - accuracy: 0.4905\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0602 - accuracy: 0.5011\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0608 - accuracy: 0.5001\n",
      "94/94 [==============================] - 0s 575us/step\n",
      "Model accuracy: 0.3436666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "# X = pd.read_csv('traindata.txt',delimiter=',',header=None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_features = pd.read_csv('traindata.txt', delimiter=',', header=None)\n",
    "\n",
    "df_labels = pd.read_csv('trainlabels.txt', header=None)\n",
    "\n",
    "# Split df_features into X_train and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_features,\n",
    "    df_labels,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(df_features.shape)\n",
    "print(df_labels.shape)\n",
    "# Assuming X_train is a Pandas Series\n",
    "# Data augmentation - random perturbations\n",
    "augmented_X_train = []\n",
    "augmented_y_train = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    original_data = X_train.iloc[i].to_numpy()\n",
    "    augmented_X_train.append(original_data)\n",
    "    augmented_y_train.append(y_train.iloc[i].values[0])\n",
    "\n",
    "    # Apply random perturbations\n",
    "    perturbed_data = original_data + np.random.normal(0, 0.1, size=original_data.shape)\n",
    "    augmented_X_train.append(perturbed_data)\n",
    "    augmented_y_train.append(y_train.iloc[i].values[0])\n",
    "\n",
    "# Convert augmented data to DataFrames\n",
    "augmented_X_train = pd.DataFrame(augmented_X_train)\n",
    "augmented_y_train = pd.DataFrame(augmented_y_train)\n",
    "\n",
    "# Concatenate augmented data with original data\n",
    "X_train = pd.concat([X_train, augmented_X_train], axis=0)\n",
    "y_train = pd.concat([y_train, augmented_y_train], axis=0)\n",
    "\n",
    "# Shuffle the augmented data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define some constants\n",
    "INPUT_SHAPE = (71,)  # Number of input features\n",
    "NUM_CLASSES = 10  # Number of output classes (0-9)\n",
    "LEARNING_RATE = 0.01  # Adjust as necessary\n",
    "\n",
    "# One-hot encoding of output\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "# Define the NN architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=INPUT_SHAPE),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define an Adam optimizer with the desired learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Compile the model with the custom optimizer\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded,\n",
    "                    epochs=30,\n",
    "                    batch_size=32)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Model accuracy:', accuracy)\n",
    "\n",
    "# Create confusion matrix\n",
    "# confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
    "# print('Confusion Matrix:')\n",
    "# print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_362 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.1896\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.3961\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.5495\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.6554\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.7339\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.7945\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.8339\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.8652\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0180 - accuracy: 0.8827\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0157 - accuracy: 0.8985\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0141 - accuracy: 0.9108\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0127 - accuracy: 0.9200\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0125 - accuracy: 0.9215\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9305\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9317\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9318\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0096 - accuracy: 0.9404\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9439\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9400\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0088 - accuracy: 0.9456\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9433\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9402\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9505\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9516\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9479\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9501\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9560\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.9539\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0079 - accuracy: 0.9503\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Model accuracy: 0.435\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_368 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.1923\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.3823\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.5494\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0476 - accuracy: 0.6551\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0379 - accuracy: 0.7370\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.7969\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0245 - accuracy: 0.8405\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.8723\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0175 - accuracy: 0.8880\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0156 - accuracy: 0.8999\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9113\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0131 - accuracy: 0.9176\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9246\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 0.9294\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9301\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9334\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9387\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9432\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9494\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9451\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9470\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9482\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9502\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9552\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0078 - accuracy: 0.9523\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9514\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9537\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.9551\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9535\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.44966666666666666\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_374 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.1862\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.4119\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.5752\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.6818\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.7591\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0278 - accuracy: 0.8133\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0228 - accuracy: 0.8508\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0190 - accuracy: 0.8767\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.8934\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0153 - accuracy: 0.9023\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9120\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9217\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9284\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9273\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9330\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9361\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0095 - accuracy: 0.9422\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0092 - accuracy: 0.9440\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9359\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 0.9430\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9516\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9439\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9479\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0073 - accuracy: 0.9562\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9536\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9491\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9503\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9570\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9579\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.435\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.1852\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0733 - accuracy: 0.3890\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.5449\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0474 - accuracy: 0.6546\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.7352\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.7937\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.8343\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0206 - accuracy: 0.8647\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0180 - accuracy: 0.8847\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0164 - accuracy: 0.8959\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0138 - accuracy: 0.9131\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0137 - accuracy: 0.9130\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9179\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9287\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9364\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9315\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9402\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0098 - accuracy: 0.9395\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9451\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9415\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9422\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9500\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9501\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9503\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9483\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9505\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9568\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0080 - accuracy: 0.9518\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9567\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9565\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.43733333333333335\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_386 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.1918\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.4101\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0575 - accuracy: 0.5623\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0469 - accuracy: 0.6621\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.7440\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0298 - accuracy: 0.8013\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0237 - accuracy: 0.8444\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.8704\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0174 - accuracy: 0.8903\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0162 - accuracy: 0.8958\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0143 - accuracy: 0.9091\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0124 - accuracy: 0.9225\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0131 - accuracy: 0.9174\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9240\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9295\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0097 - accuracy: 0.9398\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9310\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0103 - accuracy: 0.9355\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9384\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9434\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0083 - accuracy: 0.9491\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0082 - accuracy: 0.9501\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0091 - accuracy: 0.9448\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9461\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9530\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9530\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.9538\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9494\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0072 - accuracy: 0.9564\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9569\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.43966666666666665\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_392 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 3s 3ms/step - loss: 0.0865 - accuracy: 0.1974\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.4018\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.5579\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0463 - accuracy: 0.6636\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0368 - accuracy: 0.7413\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0288 - accuracy: 0.8041\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.8463\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.8728\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0169 - accuracy: 0.8914\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0147 - accuracy: 0.9060\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9083\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0126 - accuracy: 0.9195\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9269\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0116 - accuracy: 0.9276\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9295\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9353\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9415\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0101 - accuracy: 0.9370\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9402\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0103 - accuracy: 0.9356\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9487\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9461\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9498\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0087 - accuracy: 0.9471\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0074 - accuracy: 0.9542\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9492\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0086 - accuracy: 0.9469\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0078 - accuracy: 0.9519\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0080 - accuracy: 0.9513\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9562\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.4583333333333333\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_398 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 3s 3ms/step - loss: 0.0868 - accuracy: 0.1949\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0721 - accuracy: 0.4040\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.0574 - accuracy: 0.5645\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0466 - accuracy: 0.6612\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0367 - accuracy: 0.7441\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0290 - accuracy: 0.8048\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0238 - accuracy: 0.8432\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0190 - accuracy: 0.8772\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0160 - accuracy: 0.8987\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0147 - accuracy: 0.9056\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0127 - accuracy: 0.9204\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0124 - accuracy: 0.9217\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0121 - accuracy: 0.9251\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0106 - accuracy: 0.9322\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0106 - accuracy: 0.9351\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0097 - accuracy: 0.9400\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0102 - accuracy: 0.9369\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0097 - accuracy: 0.9400\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0093 - accuracy: 0.9428\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0090 - accuracy: 0.9442\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0084 - accuracy: 0.9479\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0090 - accuracy: 0.9440\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0080 - accuracy: 0.9502\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9536\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0069 - accuracy: 0.9580\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0087 - accuracy: 0.9458\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0077 - accuracy: 0.9531\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0077 - accuracy: 0.9529\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9535\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9600\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Model accuracy: 0.44866666666666666\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_404 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 4s 4ms/step - loss: 0.0873 - accuracy: 0.1814\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.4042\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0567 - accuracy: 0.5674\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.6711\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.7534\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.8186\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.8519\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.8827\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.8934\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9130\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0122 - accuracy: 0.9240\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9258\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9341\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9337\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9363\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9408\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9427\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9448\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9385\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0078 - accuracy: 0.9519\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9509\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0084 - accuracy: 0.9483\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9523\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0076 - accuracy: 0.9540\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0080 - accuracy: 0.9502\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9541\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0066 - accuracy: 0.9605\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0067 - accuracy: 0.9593\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9490\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9606\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.448\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 5s 5ms/step - loss: 0.0866 - accuracy: 0.2010\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0723 - accuracy: 0.3951\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0583 - accuracy: 0.5497\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0474 - accuracy: 0.6521\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.7332\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0300 - accuracy: 0.7957\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0240 - accuracy: 0.8408\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0202 - accuracy: 0.8676\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.8875\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0157 - accuracy: 0.8992\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0139 - accuracy: 0.9110\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9178\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0117 - accuracy: 0.9259\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9298\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0113 - accuracy: 0.9283\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9323\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9429\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9399\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9435\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0096 - accuracy: 0.9410\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0088 - accuracy: 0.9465\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0084 - accuracy: 0.9486\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9438\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0083 - accuracy: 0.9494\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9504\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9516\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0077 - accuracy: 0.9528\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9511\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9513\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0074 - accuracy: 0.9547\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model accuracy: 0.44\n",
      "(10000, 71)\n",
      "(10000, 1)\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_416 (Dense)           (None, 128)               9216      \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_420 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,802\n",
      "Trainable params: 85,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0865 - accuracy: 0.1952\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.3978\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.5559\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0479 - accuracy: 0.6499\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0383 - accuracy: 0.7296\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0307 - accuracy: 0.7929\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0246 - accuracy: 0.8378\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.8623\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0177 - accuracy: 0.8860\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.8993\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0145 - accuracy: 0.9082\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0129 - accuracy: 0.9193\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0125 - accuracy: 0.9214\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0118 - accuracy: 0.9264\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0115 - accuracy: 0.9280\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9347\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9418\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0099 - accuracy: 0.9388\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9411\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9438\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0091 - accuracy: 0.9430\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 0.0084 - accuracy: 0.9479\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9487\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0089 - accuracy: 0.9438\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9477\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9576\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.0074 - accuracy: 0.9553\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0079 - accuracy: 0.9520\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0079 - accuracy: 0.9516\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.0071 - accuracy: 0.9567\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "Model accuracy: 0.455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "for i in range(10):\n",
    "    df_features = pd.read_csv('traindata.txt', delimiter=',', header=None)\n",
    "\n",
    "    df_labels = pd.read_csv('trainlabels.txt', header=None)\n",
    "\n",
    "    # Split df_features into X_train and X_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_features,\n",
    "        df_labels,\n",
    "        test_size=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(df_features.shape)\n",
    "    print(df_labels.shape)\n",
    "    # Assuming X_train is a Pandas Series\n",
    "    # Data augmentation - random perturbations\n",
    "    augmented_X_train = []\n",
    "    augmented_y_train = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        original_data = X_train.iloc[i].to_numpy()\n",
    "        augmented_X_train.append(original_data)\n",
    "        augmented_y_train.append(y_train.iloc[i].values[0])\n",
    "\n",
    "        # Apply random perturbations\n",
    "        perturbed_data = original_data + np.random.normal(0, 0.1, size=original_data.shape)\n",
    "        augmented_X_train.append(perturbed_data)\n",
    "        augmented_y_train.append(y_train.iloc[i].values[0])\n",
    "\n",
    "    # Convert augmented data to DataFrames\n",
    "    augmented_X_train = pd.DataFrame(augmented_X_train)\n",
    "    augmented_y_train = pd.DataFrame(augmented_y_train)\n",
    "\n",
    "    # Concatenate augmented data with original data\n",
    "    X_train = pd.concat([X_train, augmented_X_train], axis=0)\n",
    "    y_train = pd.concat([y_train, augmented_y_train], axis=0)\n",
    "\n",
    "    # Shuffle the augmented data\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Define some constants\n",
    "    INPUT_SHAPE = (71,)  # Number of input features\n",
    "    NUM_CLASSES = 10  # Number of output classes (0-9)\n",
    "    LEARNING_RATE = 0.001  # Adjust as necessary\n",
    "\n",
    "    # One-hot encoding of output\n",
    "    y_train_encoded = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test_encoded = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "\n",
    "    # Define the NN architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Define an Adam optimizer with the desired learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    # Compile the model with the custom optimizer\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train_encoded,\n",
    "                        epochs=30,\n",
    "                        batch_size=32)\n",
    "\n",
    "    # Predicting the test set results\n",
    "    y_test_pred_prob = model.predict(X_test)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print('Model accuracy:', accuracy)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    # confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    # print('Confusion Matrix:')    # print(confusion_mat)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
