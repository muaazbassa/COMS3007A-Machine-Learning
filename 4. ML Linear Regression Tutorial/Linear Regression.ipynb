{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUESTION1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Predicted Value of y_hat(x) for x = 1.\n",
    "y_hat= round(0.4 + 0.8*(1),2)\n",
    "y_true = 1\n",
    "y_hat\n",
    "# The error for when x=1\n",
    "error = round(0.5 * (y_hat - y_true)**2,2)\n",
    "\n",
    "#print the y_hat and error\n",
    "print(\"y_hat = \", y_hat)\n",
    "print(\"error = \", error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Predicted Value of y_hat(x) for x = 2.\n",
    "y_hat= 0.4 + 0.8*(2)\n",
    "y_true = 3\n",
    "y_hat\n",
    "\n",
    "# The error for when x=2\n",
    "error = round(0.5 * (y_hat - y_true)**2,2)\n",
    "\n",
    "#print the y_hat and error\n",
    "print(\"y_hat = \", y_hat)\n",
    "print(\"error = \", error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of squares error for this model\n",
    "\n",
    "def y_hat(x):\n",
    "    y = 0.4 + 0.8*(x)\n",
    "    return y\n",
    "\n",
    "# x values\n",
    "x_values = [1,2,3,4,5]\n",
    "# y avlues\n",
    "y_values = [1,3,2,3,5]\n",
    "y_predicted = []\n",
    "error = 0.0\n",
    "for x in x_values:\n",
    "    y_predicted.append(round(y_hat(x),2))\n",
    "\n",
    "for i in range(len(y_values)):\n",
    "    error += 0.5 * (y_values[i] - y_predicted[i])**2\n",
    "\n",
    "error = round(error, 2)\n",
    "error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Generating random sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = 0\n",
    "std = 10\n",
    "size = 150\n",
    "\n",
    "sample = np.random.normal(mean, std, size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Constructing design matrix from sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designMatrix(s, rows, cols):\n",
    "    design = np.ones((rows, cols))\n",
    "    for i in range(cols):\n",
    "        design[:,i] = s**i\n",
    "    return design\n",
    "\n",
    "design = designMatrix(sample, 150, 3)\n",
    "\n",
    "print(design)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Sample true values for theta, (3 values - corresponds to features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.uniform(0, 1, 3)\n",
    "\n",
    "theta0 = theta[0]\n",
    "theta1 = theta[1]\n",
    "theta2 = theta[2]\n",
    "\n",
    "print(theta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Generate y values using design matrix and true parameter. Also add noise to make data more realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "std = 8\n",
    "size = 150\n",
    "\n",
    "noise = np.random.normal(mean, std, size)\n",
    "\n",
    "y = np.dot(design, theta) + noise\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Plot sample data with generated y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(sample, y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi. Split sample data into training, testing and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#90 of 150 for training (60%)\n",
    "#30 of 150 for testing (20%)\n",
    "#30 of 150 for validation (20%)\n",
    "\n",
    "#Training\n",
    "training_x_values = sample[:90]\n",
    "training_y_values = y[:90]\n",
    "trainDM = design[:90]\n",
    "\n",
    "#Testing\n",
    "testing_x_values = sample[120:150]\n",
    "testing_y_values = y[120:150]\n",
    "testDM = design[120:150]\n",
    "\n",
    "#Validation\n",
    "validation_x_values = sample[90:120]\n",
    "validation_y_values = y[90:120]\n",
    "validDM = design[90:120]\n",
    "\n",
    "# print(training_x_values)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Use Moore-Penrose pseudo-inverse to calculate the closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moorePenrose(DMatrix, y_values):\n",
    "    dmTranspose = np.transpose(DMatrix)\n",
    "    firstPart = np.linalg.inv(np.dot(dmTranspose, DMatrix))\n",
    "    secondPart = np.dot(dmTranspose, y_values)\n",
    "    finalMoore = np.dot(firstPart, secondPart)\n",
    "    return finalMoore\n",
    "\n",
    "moore_penrose = moorePenrose(trainDM, training_y_values)\n",
    "\n",
    "print(moore_penrose)\n",
    "print(theta)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. How close are the learned parameter values to the true parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learned parameter values, with the exception of theta0, which is off from the true value by a significant value.\n",
    "# While theta1 is off by approx. 0.004 and theta2 is off by approx 0.005, which is relatively close to the true parameters  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Compute the training and validation error of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def Error(x_values, y_values):\n",
    "    sum = 0\n",
    "    index = 0\n",
    "\n",
    "    for x in x_values:\n",
    "        y_predicted = moore_penrose[0] + moore_penrose[1] * x + moore_penrose[2] * math.pow(x, 2)\n",
    "        error = y_values[index] - y_predicted\n",
    "        sum += math.pow(error,2)\n",
    "        index += 1\n",
    "\n",
    "    totalError = (1 / (2 * 150)) * sum # Since the fraction is valid as long as its a constant (slides)\n",
    "    return totalError, y_predicted\n",
    "\n",
    "trainingError, training_y = Error(training_x_values, training_y_values)\n",
    "validationError, validated_y = Error(validation_x_values, validation_y_values)\n",
    "\n",
    "print(trainingError)\n",
    "print(validationError)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Plot of the data and the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted_trainX = trainDM[trainDM[:,1].argsort()]\n",
    "yValues = np.dot(sorted_trainX, moore_penrose)\n",
    "\n",
    "\n",
    "plt.scatter(sample, y)\n",
    "plt.plot(sorted_trainX[:,1], yValues, \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Repeat the above process using Gradient Descent to train your model. In addition, plot the\n",
    "training error of your regression model over time (observe or capture the training error every 20\n",
    "parameter updates/time steps). Your plot should look like Figure 2c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(X, y, learning_rate=0.0000001, num_iterations=1000):\n",
    "    # Initialize parameters\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    errors = []\n",
    "\n",
    "    # Perform gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        # Compute predictions\n",
    "        y_pred = X.dot(theta)\n",
    "\n",
    "        # Compute errors\n",
    "        error = y_pred - y\n",
    "        errors.append(np.mean(error**2))\n",
    "\n",
    "        # Compute gradients\n",
    "        grad = (2/m) * X.T.dot(error)\n",
    "\n",
    "        # Update parameters\n",
    "        theta = theta - learning_rate * grad\n",
    "\n",
    "    return theta, errors\n",
    "\n",
    "\n",
    "theta,error = gradient_descent(trainDM,training_y)\n",
    "\n",
    "plt.plot(error,color=\"orange\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
